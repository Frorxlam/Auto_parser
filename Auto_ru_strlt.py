import streamlit as st
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import time
import re

# Page config
st.set_page_config(
    page_title="–ü–∞—Ä—Å–µ—Ä Auto.ru",
    page_icon="üöó",
    layout="wide"
)

st.title("üöó –ü–∞—Ä—Å–µ—Ä –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π Auto.ru")
st.markdown("–í–≤–µ–¥–∏—Ç–µ URL —Å Auto.ru –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π")

# URL input
url_input = st.text_input(
    "–í–≤–µ–¥–∏—Ç–µ URL Auto.ru:",
    placeholder="https://auto.ru/cars/new/group/...",
    help="–í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É —Å Auto.ru. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –Ω–æ–≤—ã–µ –∏–ª–∏ –±/—É –∞–≤—Ç–æ–º–æ–±–∏–ª–∏."
)

def setup_driver():
    """Setup Selenium WebDriver"""
    options = Options()
    options.add_argument("--start-maximized")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--headless")  # Run in headless mode for Streamlit
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=options)

def parse_new_vehicles(base_url):
    """Parser for new vehicles"""
    driver = setup_driver()
    
    def parse_page(url):
        driver.get(url)

        try:
            WebDriverWait(driver, 5).until(
                EC.presence_of_element_located((By.XPATH, "//iframe[contains(@src, 'captcha')]"))
            )
            st.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞. –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –≤—Ä—É—á–Ω—É—é.")
            return []
        except:
            pass  # No captcha found

        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, 'CardGroupListingItem'))
            )
        except:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
            return []

        html = driver.page_source
        soup = BeautifulSoup(html, 'html.parser')

        model_links = soup.find_all('a', class_='Link CardGroupListingItem__titleLink')
        brand_element = soup.find('h1', class_='CardGroupHeaderDesktop__title-nZZMr')
        brand_name = brand_element.text.strip().replace("–ö—É–ø–∏—Ç—å", "")[:-10] if brand_element else "Unknown"
        prices = soup.find_all('span', class_='OfferPriceCaption__price')
        dealers = soup.find_all('a', class_='Link CardGroupListingItemFooter__dealerName')
        specs = soup.find_all('div', class_='CardGroupListingItem__techSummary')
        stocks = soup.find_all('ul', class_='CardGroupListingItem__horizontalList')
        cities = soup.find_all('span', class_='MetroListPlace__regionName MetroListPlace_nbsp')

        data = []
        min_length = min(len(model_links), len(prices), len(dealers), len(specs), len(stocks), len(cities))
        
        for i in range(min_length):
            model_name = model_links[i].text.strip()
            price_value = prices[i].text.strip()
            dealer_value = dealers[i].text.strip()
            specs_value = ' '.join(div.get_text(strip=True) for div in specs[i].find_all('div'))
            stock_value = stocks[i].text.strip()
            city_value = cities[i].text.strip()
            data.append([brand_name, model_name, price_value, dealer_value, specs_value, stock_value, city_value])

        return data

    # Parse pages
    all_data = []
    
    # First page
    with st.spinner("–ü–∞—Ä—Å–∏–Ω–≥ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã..."):
        page_data = parse_page(base_url)
        all_data.extend(page_data)

    # Check for pagination
    html = driver.page_source
    soup = BeautifulSoup(html, 'html.parser')
    pagination = soup.find_all('a', class_='Button Button_color_whiteHoverBlue Button_disabled Button_checked Button_size_s Button_type_link Button_width_default ListingPagination__page')

    if pagination:
        progress_bar = st.progress(0)
        for page_num in range(2, 11):  # Limit to 10 pages for demo
            url = f"{base_url}?page={page_num}"
            try:
                with st.spinner(f"–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}..."):
                    page_data = parse_page(url)
                    if not page_data:
                        break
                    all_data.extend(page_data)
                    progress_bar.progress(min(page_num / 10, 1.0))
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}: {e}")
                break

    driver.quit()
    
    # Create DataFrame
    df = pd.DataFrame(all_data, columns=['–ú–æ–¥–µ–ª—å', '–ö–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—è', '–¶–µ–Ω–∞', '–î–∏–ª–µ—Ä', '–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è', '–ù–∞–ª–∏—á–∏–µ', '–ì–æ—Ä–æ–¥'])
    
    # Parse specifications
    if not df.empty:
        df = parse_specifications(df)
        # Clean price data
        df['–¶–µ–Ω–∞'] = df['–¶–µ–Ω–∞'].str.replace(r'[^\d]', '', regex=True)
        df['–¶–µ–Ω–∞'] = pd.to_numeric(df['–¶–µ–Ω–∞'], errors='coerce')
    
    return df

def parse_used_vehicles(base_url):
    """Parser for used vehicles"""
    driver = setup_driver()
    
    def parse_page(url):
        driver.get(url)

        try:
            WebDriverWait(driver, 5).until(
                EC.presence_of_element_located((By.XPATH, "//iframe[contains(@src, 'captcha')]"))
            )
            st.warning("Captcha detected. Please handle manually if needed.")
            return []
        except:
            pass  # No captcha found

        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, 'ListingItem__title'))
            )
        except:
            st.error("Failed to load page elements")
            return []

        html = driver.page_source
        soup = BeautifulSoup(html, 'html.parser')

        model_blocks = soup.find_all('div', class_='ListingItem__title')
        specs_blocks = soup.find_all('div', class_='ListingItemTechSummaryDesktop ListingItem__techSummary')
        cities = soup.find_all('span', class_='MetroListPlace__regionName MetroListPlace_nbsp')
        years = soup.find_all('div', class_='ListingItem__year')
        mileages = soup.find_all('div', class_='ListingItem__kmAge')
        prices = soup.find_all('div', class_='ListingItemPrice__content')

        brand_name_tag = soup.find('h1', class_='CardGroupHeaderDesktop__title-nZZMr')
        brand_name = brand_name_tag.text.strip().replace("–ö—É–ø–∏—Ç—å", "")[:-10] if brand_name_tag else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

        data = []
        min_length = min(len(model_blocks), len(specs_blocks), len(cities), len(years), len(mileages), len(prices))

        for i in range(min_length):
            model_name = model_blocks[i].get_text(strip=True)
            specs_value = ' '.join(div.get_text(strip=True) for div in specs_blocks[i].find_all('div'))
            city_value = cities[i].text.strip()
            year_value = years[i].text.strip()
            mileage_value = mileages[i].text.strip().replace('\xa0', ' ').replace('–∫–º', '').strip()
            price_value = prices[i].text.strip().replace('\xa0', ' ').replace('‚ÇΩ', '').strip()

            # Filter out high mileage (over 1000 km as per your logic)
            try:
                mileage_num = int(mileage_value.replace(' ', '').replace(',', ''))
                if mileage_num > 1000:
                    continue
            except:
                continue

            data.append([brand_name, model_name, specs_value, city_value, year_value, mileage_value, price_value])

        return data

    # Parse pages
    all_data = []
    
    # First page
    with st.spinner("Parsing first page..."):
        page_data = parse_page(base_url)
        all_data.extend(page_data)

    # Check for pagination
    html = driver.page_source
    soup = BeautifulSoup(html, 'html.parser')
    pagination = soup.find_all('a', class_='Button Button_color_whiteHoverBlue Button_disabled Button_checked Button_size_s Button_type_link Button_width_default ListingPagination__page')

    if pagination:
        progress_bar = st.progress(0)
        for page_num in range(2, 11):  # Limit to 10 pages for demo
            url = f"{base_url}?page={page_num}"
            try:
                with st.spinner(f"Parsing page {page_num}..."):
                    page_data = parse_page(url)
                    if not page_data:
                        break
                    all_data.extend(page_data)
                    progress_bar.progress(min(page_num / 10, 1.0))
            except Exception as e:
                st.error(f"Error on page {page_num}: {e}")
                break

    driver.quit()
    
    # Create DataFrame
    columns = ['–ú–∞—Ä–∫–∞', '–ú–æ–¥–µ–ª—å', '–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è', '–ì–æ—Ä–æ–¥', '–ì–æ–¥ –≤—ã–ø—É—Å–∫–∞', '–ü—Ä–æ–±–µ–≥', '–¶–µ–Ω–∞']
    df = pd.DataFrame(all_data, columns=columns)
    
    # Parse specifications for used vehicles
    if not df.empty:
        df = parse_used_specifications(df)
        # Clean price data
        df['–¶–µ–Ω–∞'] = df['–¶–µ–Ω–∞'].str.replace(r'[^\d]', '', regex=True)
        df['–¶–µ–Ω–∞'] = pd.to_numeric(df['–¶–µ–Ω–∞'], errors='coerce')
    
    return df

def parse_used_specifications(df):
    """Parse used vehicle specifications"""
    trans_dict = {
        '–º–µ—Ö–∞–Ω–∏–∫–∞': 'MT',
        '–º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∞—è': 'MT',
        '–≤–∞—Ä–∏–∞—Ç–æ—Ä': 'CVT',
        '—Ä–æ–±–æ—Ç': 'AMT',
        '–∞–≤—Ç–æ–º–∞—Ç': 'AT',
        '–∞–∫–ø–ø': 'AT',
        'cvt': 'CVT'
    }

    def parse_row(text):
        result = {}

        # Engine volume, power, fuel
        match = re.search(r'(\d+\.\d)\s*–ª.?[\s\u2009]*/[\s\u2009]*(\d+)\s*–ª\.—Å\..?/[\s\u2009]*(\w+)', text)
        if match:
            result['engine_volume'] = match.group(1)
            result['power'] = int(match.group(2))
            result['fuel_type'] = match.group(3)

        # Transmission
        for word, code in trans_dict.items():
            if re.search(rf'\b{word}\b', text, flags=re.IGNORECASE):
                result['transmission'] = code
                break
        else:
            result['transmission'] = None

        # Drive type
        if '–ø–µ—Ä–µ–¥–Ω–∏–π' in text:
            result['drive'] = 'FWD'
        elif '–ø–æ–ª–Ω—ã–π' in text:
            result['drive'] = 'AWD'
        elif '–∑–∞–¥–Ω–∏–π' in text:
            result['drive'] = 'RWD'
        else:
            result['drive'] = None

        # Color
        drive_match = re.search(r'(–ø–µ—Ä–µ–¥–Ω–∏–π|–ø–æ–ª–Ω—ã–π|–∑–∞–¥–Ω–∏–π)\s+(\w+)', text)
        if drive_match:
            result['color'] = drive_match.group(2)

        # Base options
        base_match = re.search(r'(\d+)\s+–±–∞–∑–æ–≤\w* –æ–ø—Ü\w*', text)
        if base_match:
            result['base_options'] = int(base_match.group(1))

        # Extra options
        extra_match = re.search(r'(\d+)\s+–¥–æ–ø\.?\s+–æ–ø—Ü\w*', text)
        if extra_match:
            result['extra_options'] = int(extra_match.group(1))

        return pd.Series(result)

    parsed = df['–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è'].apply(parse_row)
    # Drop '–ú–∞—Ä–∫–∞' column and concat with parsed data
    df_without_marka = df.drop(columns=['–ú–∞—Ä–∫–∞']) if '–ú–∞—Ä–∫–∞' in df.columns else df
    return pd.concat([df_without_marka, parsed], axis=1)

def parse_specifications(df):
    """Parse new vehicle specifications"""
    trans_dict = {
        '–º–µ—Ö–∞–Ω–∏–∫–∞': 'MT',
        '–º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∞—è': 'MT',
        '–≤–∞—Ä–∏–∞—Ç–æ—Ä': 'CVT',
        '—Ä–æ–±–æ—Ç': 'AMT',
        '–∞–≤—Ç–æ–º–∞—Ç': 'AT',
        '–∞–∫–ø–ø': 'AT',
        'cvt': 'CVT'
    }

    fuel_dict = {
        '–¥–∏–∑–µ–ª—å': '–î–∏–∑–µ–ª—å',
        '–±–µ–Ω–∑–∏–Ω': '–ë–µ–Ω–∑–∏–Ω',
        '—ç–ª–µ–∫—Ç—Ä–æ': '–≠–ª–µ–∫—Ç—Ä–æ',
        '–≥–∏–±—Ä–∏–¥': '–ì–∏–±—Ä–∏–¥',
        '–≥–∞–∑': '–ì–∞–∑'
    }

    def parse_row(text):
        result = {}

        # Engine volume and power
        match = re.search(r'(\d+\.\d)\s*–ª.?[\s\u2009]*/[\s\u2009]*(\d+)\s*–ª\.—Å\.', text)
        if match:
            result['engine_volume'] = match.group(1)
            result['power'] = int(match.group(2))

        # Fuel type
        for key, value in fuel_dict.items():
            if key in text.lower():
                result['fuel_type'] = value
                break
        else:
            result['fuel_type'] = None

        # Transmission
        for word, code in trans_dict.items():
            if re.search(rf'\b{word}\b', text, flags=re.IGNORECASE):
                result['transmission'] = code
                break
        else:
            result['transmission'] = None

        # Drive type
        if '–ø–µ—Ä–µ–¥–Ω–∏–π' in text:
            result['drive'] = 'FWD'
        elif '–ø–æ–ª–Ω—ã–π' in text:
            result['drive'] = 'AWD'
        elif '–∑–∞–¥–Ω–∏–π' in text:
            result['drive'] = 'RWD'
        else:
            result['drive'] = None

        # Color
        drive_match = re.search(r'(–ø–µ—Ä–µ–¥–Ω–∏–π|–ø–æ–ª–Ω—ã–π|–∑–∞–¥–Ω–∏–π)\s+(\w+)', text)
        if drive_match:
            result['color'] = drive_match.group(2)

        # Base options
        base_match = re.search(r'(\d+)\s+–±–∞–∑–æ–≤\w* –æ–ø—Ü\w*', text)
        if base_match:
            result['base_options'] = int(base_match.group(1))

        # Extra options
        extra_match = re.search(r'(\d+)\s+–¥–æ–ø\.?\s+–æ–ø—Ü\w*', text)
        if extra_match:
            result['extra_options'] = int(extra_match.group(1))

        return pd.Series(result)

    parsed = df['–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è'].apply(parse_row)
    return pd.concat([df, parsed], axis=1)

def detect_parser_type(url):
    """Detect if URL is for new or used vehicles"""
    url_lower = url.lower()
    if 'new' in url_lower:
        return 'new'
    elif 'used' in url_lower:
        return 'used'
    else:
        return None

# Main app logic
if url_input:
    if not url_input.startswith('http'):
        st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL, –Ω–∞—á–∏–Ω–∞—é—â–∏–π—Å—è —Å http:// –∏–ª–∏ https://")
    else:
        parser_type = detect_parser_type(url_input)
        
        if parser_type is None:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π –ø–æ URL. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ URL —Å–æ–¥–µ—Ä–∂–∏—Ç 'new' –∏–ª–∏ 'used'")
        else:
            vehicle_type = "–ù–û–í–´–ï" if parser_type == 'new' else "–ë/–£"
            st.success(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã: **{vehicle_type}** –∞–≤—Ç–æ–º–æ–±–∏–ª–∏")
            
            if st.button("üöÄ –ù–∞—á–∞—Ç—å –ø–∞—Ä—Å–∏–Ω–≥", type="primary"):
                try:
                    if parser_type == 'new':
                        df = parse_new_vehicles(url_input)
                    else:
                        df = parse_used_vehicles(url_input)
                    
                    if not df.empty:
                        st.success(f"–£—Å–ø–µ—à–Ω–æ —Å–ø–∞—Ä—Å–µ–Ω–æ {len(df)} –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π!")
                        
                        # Display results
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.subheader("üìä –î–∞–Ω–Ω—ã–µ")
                            st.dataframe(df, use_container_width=True)
                        
                        with col2:
                            st.subheader("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
                            if '–¶–µ–Ω–∞' in df.columns:
                                price_col = df['–¶–µ–Ω–∞'].dropna()
                                if not price_col.empty:
                                    st.metric("–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞", f"{price_col.mean():,.0f} ‚ÇΩ")
                                    st.metric("–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞", f"{price_col.min():,.0f} ‚ÇΩ")
                                    st.metric("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞", f"{price_col.max():,.0f} ‚ÇΩ")
                            
                            # Price range by complectation with specifications
                            complectation_col = '–ö–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—è' if parser_type == 'new' else '–ú–æ–¥–µ–ª—å'
                            if complectation_col in df.columns and '–¶–µ–Ω–∞' in df.columns:
                                st.write("**–î–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–Ω –ø–æ –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—è–º:**")
                                
                                # Group by complectation and get stats
                                price_stats = df.groupby(complectation_col).agg({
                                    '–¶–µ–Ω–∞': ['min', 'max', 'count', lambda x: x.mode().iloc[0] if not x.mode().empty else x.median()],
                                    'engine_volume': lambda x: x.mode().iloc[0] if 'engine_volume' in df.columns and not x.dropna().empty and not x.dropna().mode().empty else None,
                                    'power': lambda x: x.mode().iloc[0] if 'power' in df.columns and not x.dropna().empty and not x.dropna().mode().empty else None,
                                    'fuel_type': lambda x: x.mode().iloc[0] if 'fuel_type' in df.columns and not x.dropna().empty and not x.dropna().mode().empty else None,
                                    'transmission': lambda x: x.mode().iloc[0] if 'transmission' in df.columns and not x.dropna().empty and not x.dropna().mode().empty else None,
                                    'drive': lambda x: x.mode().iloc[0] if 'drive' in df.columns and not x.dropna().empty and not x.dropna().mode().empty else None
                                }).reset_index()
                                
                                # Flatten column names
                                price_stats.columns = [
                                    complectation_col, 'min_price', 'max_price', 'count', 'mode_price',
                                    'engine_volume', 'power', 'fuel_type', 'transmission', 'drive'
                                ]
                                
                                # Calculate potential price using the formula
                                price_stats['potential_price'] = price_stats['mode_price'].apply(
                                    lambda x: int(round((x * 0.97 / 0.85 + 250_000) / 1000) * 1000) if pd.notnull(x) else None
                                )
                                
                                price_stats = price_stats.sort_values('min_price')
                                
                                for _, row in price_stats.head(10).iterrows():  # Show top 10
                                    complectation = row[complectation_col]
                                    min_price = row['min_price']
                                    max_price = row['max_price']
                                    count = row['count']
                                    potential_price = row['potential_price']
                                    
                                    # Build specifications string
                                    specs = []
                                    if pd.notnull(row['engine_volume']):
                                        specs.append(f"{row['engine_volume']}–ª")
                                    if pd.notnull(row['power']):
                                        specs.append(f"{int(row['power'])}–ª.—Å.")
                                    if pd.notnull(row['fuel_type']):
                                        specs.append(str(row['fuel_type']))
                                    if pd.notnull(row['transmission']):
                                        specs.append(str(row['transmission']))
                                    if pd.notnull(row['drive']):
                                        specs.append(str(row['drive']))
                                    
                                    specs_str = " | ".join(specs) if specs else ""
                                    
                                    # Display complectation info
                                    if min_price == max_price:
                                        price_display = f"{min_price:,.0f} ‚ÇΩ"
                                    else:
                                        price_display = f"{min_price:,.0f} - {max_price:,.0f} ‚ÇΩ"
                                    
                                    potential_display = f" ‚Üí **{potential_price:,.0f} ‚ÇΩ**" if potential_price else ""
                                    specs_display = f" ({specs_str})" if specs_str else ""
                                    
                                    st.write(f"‚Ä¢ **{complectation}**{specs_display}: {price_display}{potential_display} ({count} —à—Ç.)")
                            
                            if '–ì–æ—Ä–æ–¥' in df.columns:
                                st.write("**–¢–æ–ø –≥–æ—Ä–æ–¥–æ–≤:**")
                                city_counts = df['–ì–æ—Ä–æ–¥'].value_counts().head(5)
                                for city, count in city_counts.items():
                                    st.write(f"‚Ä¢ {city}: {count}")
                            
                            # Additional stats for used vehicles
                            if parser_type == 'used':
                                if '–ì–æ–¥ –≤—ã–ø—É—Å–∫–∞' in df.columns:
                                    year_col = df['–ì–æ–¥ –≤—ã–ø—É—Å–∫–∞'].dropna()
                                    if not year_col.empty:
                                        st.write("**–î–∏–∞–ø–∞–∑–æ–Ω –≥–æ–¥–æ–≤:**")
                                        st.write(f"‚Ä¢ –°–∞–º—ã–π –Ω–æ–≤—ã–π: {year_col.max()}")
                                        st.write(f"‚Ä¢ –°–∞–º—ã–π —Å—Ç–∞—Ä—ã–π: {year_col.min()}")
                                
                                if 'transmission' in df.columns:
                                    st.write("**–ö–æ—Ä–æ–±–∫–∏ –ø–µ—Ä–µ–¥–∞—á:**")
                                    trans_counts = df['transmission'].value_counts().head(3)
                                    for trans, count in trans_counts.items():
                                        if pd.notna(trans):
                                            st.write(f"‚Ä¢ {trans}: {count}")
                        
                        # Download button
                        csv = df.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            label="üì• –°–∫–∞—á–∞—Ç—å CSV",
                            data=csv,
                            file_name=f"auto_ru_{parser_type}_vehicles.csv",
                            mime="text/csv"
                        )
                    else:
                        st.warning("–î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ URL –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
                        
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}")

# Sidebar with info
with st.sidebar:
    st.header("‚ÑπÔ∏è –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å")
    st.markdown("""
    1. **–°–∫–æ–ø–∏—Ä—É–π—Ç–µ URL** —Å Auto.ru
    2. **–í—Å—Ç–∞–≤—å—Ç–µ** –µ–≥–æ –≤ –ø–æ–ª–µ –≤–≤–æ–¥–∞
    3. **–ù–∞–∂–º–∏—Ç–µ** "–ù–∞—á–∞—Ç—å –ø–∞—Ä—Å–∏–Ω–≥"
    4. **–°–∫–∞—á–∞–π—Ç–µ** —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV
    
    **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ URL:**
    - –ù–æ–≤—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏: URL —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ "new"
    - –ë/–£ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏: URL —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ "used"
    """)
    
    st.header("‚ö° –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏")
    st.markdown("""
    - –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π
    - –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
    - –ü–∞—Ä—Å–∏–Ω–≥ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
    - –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV
    - –ü–æ–∫–∞–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    - –†–∞—Å—á–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã
    """)